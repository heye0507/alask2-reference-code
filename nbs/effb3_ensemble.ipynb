{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import sklearn\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "DATA_ROOT_PATH = '/home/heye0507/alask2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "def get_net():\n",
    "    net = EfficientNet.from_pretrained('efficientnet-b3',num_classes=4)\n",
    "    return net\n",
    "\n",
    "net = get_net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_0_best.bin  fold_2_best.bin  fold_4_best.bin\r\n",
      "fold_1_best.bin  fold_3_best.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_ROOT_PATH}/models/ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'{DATA_ROOT_PATH}/models/effb3_fold0/last-checkpoint.bin')\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "net.float().eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSubmissionRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, image_names, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_names = image_names\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_name = self.image_names[index]\n",
    "        image = cv2.imread(f'{DATA_ROOT_PATH}/data/Test/{image_name}', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "\n",
    "        return image_name, image\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_names.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            A.Normalize(p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetSubmissionRetriever(\n",
    "    image_names=np.array([path.split('/')[-1] for path in glob('/home/heye0507/alask2/data/Test/*.jpg')]),\n",
    "    transforms=get_valid_transforms(),\n",
    ")\n",
    "\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 22.3 s, total: 1min 35s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result = {'Id': [], 'Label': []}\n",
    "for step, (image_names, images) in enumerate(data_loader):\n",
    "    print(step, end='\\r')\n",
    "    \n",
    "    y_pred = net(images.cuda())\n",
    "    y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n",
    "    \n",
    "    result['Id'].extend(image_names)\n",
    "    result['Label'].extend(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0997.jpg</td>\n",
       "      <td>0.687479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3341.jpg</td>\n",
       "      <td>0.543514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005.jpg</td>\n",
       "      <td>0.120085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4807.jpg</td>\n",
       "      <td>0.718181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0727.jpg</td>\n",
       "      <td>0.725446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id     Label\n",
       "0  0997.jpg  0.687479\n",
       "1  3341.jpg  0.543514\n",
       "2  2005.jpg  0.120085\n",
       "3  4807.jpg  0.718181\n",
       "4  0727.jpg  0.725446"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(result)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 137k/137k [00:01<00:00, 70.8kB/s]\n",
      "Successfully submitted to ALASKA2 Image Steganalysis"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c alaska2-image-steganalysis -f /home/heye0507/alask2/nbs/submission.csv -m effb3_ens_no3_notta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlaskTTA:\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "    image_size = 512\n",
    "\n",
    "    def augment(self, image):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def batch_augment(self, images):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TTABypass(AlaskTTA):\n",
    "    '''author: @dreamdragon'''\n",
    "    \n",
    "    def augment(self,image):\n",
    "        return image\n",
    "    \n",
    "    def batch_augment(self,images):\n",
    "        return images\n",
    "    \n",
    "    def deaugment_boxes(self,boxes):\n",
    "        return boxes\n",
    "\n",
    "class TTAHorizontalFlip(AlaskTTA):\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "\n",
    "    def augment(self, image):\n",
    "        return image.flip(1)\n",
    "    \n",
    "    def batch_augment(self, images):\n",
    "        return images.flip(2)\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        boxes[:, [1,3]] = self.image_size - boxes[:, [3,1]]\n",
    "        return boxes\n",
    "\n",
    "class TTAVerticalFlip(AlaskTTA):\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "    \n",
    "    def augment(self, image):\n",
    "        return image.flip(2)\n",
    "    \n",
    "    def batch_augment(self, images):\n",
    "        return images.flip(3)\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        boxes[:, [0,2]] = self.image_size - boxes[:, [2,0]]\n",
    "        return boxes\n",
    "    \n",
    "class TTARotate90(AlaskTTA):\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "    \n",
    "    def augment(self, image):\n",
    "        return torch.rot90(image, 1, (1, 2))\n",
    "\n",
    "    def batch_augment(self, images):\n",
    "        return torch.rot90(images, 1, (2, 3))\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        res_boxes = boxes.copy()\n",
    "        res_boxes[:, [0,2]] = self.image_size - boxes[:, [1,3]]\n",
    "        res_boxes[:, [1,3]] = boxes[:, [2,0]]\n",
    "        return res_boxes\n",
    "\n",
    "class TTACompose(AlaskTTA):\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def augment(self, image):\n",
    "        for transform in self.transforms:\n",
    "            image = transform.augment(image)\n",
    "        return image\n",
    "    \n",
    "    def batch_augment(self, images):\n",
    "        for transform in self.transforms:\n",
    "            images = transform.batch_augment(images)\n",
    "        return images\n",
    "    \n",
    "    def prepare_boxes(self, boxes):\n",
    "        result_boxes = boxes.copy()\n",
    "        result_boxes[:,0] = np.min(boxes[:, [0,2]], axis=1)\n",
    "        result_boxes[:,2] = np.max(boxes[:, [0,2]], axis=1)\n",
    "        result_boxes[:,1] = np.min(boxes[:, [1,3]], axis=1)\n",
    "        result_boxes[:,3] = np.max(boxes[:, [1,3]], axis=1)\n",
    "        return result_boxes\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        for transform in self.transforms[::-1]:\n",
    "            boxes = transform.deaugment_boxes(boxes)\n",
    "        return self.prepare_boxes(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_transforms = [\n",
    "    TTABypass(),\n",
    "    TTAHorizontalFlip(),\n",
    "    TTAVerticalFlip(),\n",
    "    TTAHorizontalFlip(),TTAVerticalFlip(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\r"
     ]
    }
   ],
   "source": [
    "result = {'Id': [], 'Label': []}\n",
    "for step, (image_names,images) in enumerate(data_loader):\n",
    "    print(step, end='\\r')\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        predictions = []\n",
    "        for tta_transform in tta_transforms:\n",
    "\n",
    "            y_pred = net(tta_transform.batch_augment(images.clone()))\n",
    "            y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n",
    "\n",
    "            predictions.append(y_pred)\n",
    "\n",
    "        result['Id'].extend(image_names)\n",
    "        result['Label'].extend(np.mean(predictions,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    f'{DATA_ROOT_PATH}/models/ensemble/fold_0_best.bin',\n",
    "    f'{DATA_ROOT_PATH}/models/ensemble/fold_1_best.bin',\n",
    "    f'{DATA_ROOT_PATH}/models/ensemble/fold_2_best.bin',\n",
    "    #f'{DATA_ROOT_PATH}/models/ensemble/fold_3_best.bin',\n",
    "    f'{DATA_ROOT_PATH}/models/ensemble/fold_4_best.bin',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\r"
     ]
    }
   ],
   "source": [
    "result = {'Id': [], 'Label': []}\n",
    "for step, (image_names,images) in enumerate(data_loader):\n",
    "    print(step, end='\\r')\n",
    "    predictions = []\n",
    "    for model_path in models:\n",
    "        checkpoint = torch.load(model_path)\n",
    "        net.load_state_dict(checkpoint['model_state_dict']);\n",
    "        net.float().eval();\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            #predictions = []\n",
    "            y_pred = net(images.cuda())\n",
    "            y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n",
    "            predictions.append(y_pred)\n",
    "#             for tta_transform in tta_transforms:\n",
    "\n",
    "#                 y_pred = net(tta_transform.batch_augment(images.clone()))\n",
    "#                 y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n",
    "\n",
    "#                 predictions.append(y_pred)\n",
    "\n",
    "    result['Id'].extend(image_names)\n",
    "    result['Label'].extend(np.mean(predictions,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0997.jpg</td>\n",
       "      <td>0.680409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3341.jpg</td>\n",
       "      <td>0.596367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005.jpg</td>\n",
       "      <td>0.127029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4807.jpg</td>\n",
       "      <td>0.718899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0727.jpg</td>\n",
       "      <td>0.683682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id     Label\n",
       "0  0997.jpg  0.680409\n",
       "1  3341.jpg  0.596367\n",
       "2  2005.jpg  0.127029\n",
       "3  4807.jpg  0.718899\n",
       "4  0727.jpg  0.683682"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(result)\n",
    "submission.to_csv('submission_ens.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble w TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    f'{DATA_ROOT_PATH}/models/ensemble/fold_0_best.bin',\n",
    "    f'{DATA_ROOT_PATH}/models/ensemble/fold_1_best.bin',\n",
    "    #f'{DATA_ROOT_PATH}/models/ensemble/fold_2_best.bin',\n",
    "    #f'{DATA_ROOT_PATH}/models/ensemble/fold_3_best.bin',\n",
    "    f'{DATA_ROOT_PATH}/models/ensemble/fold_4_best.bin',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 31s, sys: 6min 9s, total: 27min 41s\n",
      "Wall time: 27min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = {'Id': [], 'Label': []}\n",
    "for step, (image_names,images) in enumerate(data_loader):\n",
    "    print(step, end='\\r')\n",
    "    predictions = []\n",
    "    for model_path in models:\n",
    "        checkpoint = torch.load(model_path)\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        net.float().eval()\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            #predictions = []\n",
    "            for tta_transform in tta_transforms:\n",
    "\n",
    "                y_pred = net(tta_transform.batch_augment(images.clone()))\n",
    "                y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n",
    "\n",
    "                predictions.append(y_pred)\n",
    "\n",
    "    result['Id'].extend(image_names)\n",
    "    result['Label'].extend(np.mean(predictions,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0997.jpg</td>\n",
       "      <td>0.687930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3341.jpg</td>\n",
       "      <td>0.580824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005.jpg</td>\n",
       "      <td>0.167066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4807.jpg</td>\n",
       "      <td>0.728287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0727.jpg</td>\n",
       "      <td>0.587001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id     Label\n",
       "0  0997.jpg  0.687930\n",
       "1  3341.jpg  0.580824\n",
       "2  2005.jpg  0.167066\n",
       "3  4807.jpg  0.728287\n",
       "4  0727.jpg  0.587001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(result)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python37764bitfastai2conda083c600ae6d54f50a73a18c04ce04a99"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
